{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **IMPORTING THE LIBRARIES**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# agree =0 \n# disagree = 1\n# discuss = 2\n# unrelated = 3\n\nimport sys\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Conv1D, MaxPooling1D\n\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report, accuracy_score\n\nimport pickle\n\n#definitions\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **DEFINING BASIC FUNCTIONS**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def rem_stopwords(df_list):\n    clean_list = []\n    for row in df_list:\n        clean_list.append([word for word in word_tokenize(row.lower()) if word not in stopwords.words('english')])\n    return clean_list\n\ndef listtostring(lists):\n    comb = [' '.join(row) for row in lists]\n    return comb\n\ndef tfidfer(text_from_df):\n    corpus = [rows for rows in text_from_df]\n    vectorizer.fit(corpus)\n\ndef transform(text):\n    corpus = [rows for rows in text]\n    vectors = vectorizer.transform(corpus)\n    vectors = vectors.toarray()\n    return vectors","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **LOADING THE DATASETS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH  = '../input/dataset/'\n\n#reading all files\ntrain_bodies_files = pd.read_csv(PATH + 'train_bodies.csv')\ntrain_stances_files = pd.read_csv(PATH + 'train_stances.csv')\ntest_bodies = pd.read_csv(PATH + 'test_bodies.csv')\ntest_stances = pd.read_csv(PATH + 'test_stances_unlabeled.csv')\nprint(\"read success\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **REMOVING STOP WORDS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train remove stopwords\nclean_headlines = rem_stopwords(train_stances_files.Headline.tolist())\nclean_bodies = rem_stopwords(train_bodies_files.articleBody.tolist())\nprint(\"removed train stop words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test remove stopwords\ntest_clean_headlines = rem_stopwords(test_stances.Headline.tolist())\ntest_clean_bodies = rem_stopwords(test_bodies.articleBody.tolist())\nprint(\"removed test stopwords\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **COMBINING ALL TOKENS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining all tokens to string\nclean_headlines = listtostring(clean_headlines)\nclean_bodies = listtostring(clean_bodies)\ntest_clean_headlines = listtostring(test_clean_headlines)\ntest_clean_bodies = listtostring(test_clean_bodies)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting train lists to dataframe\nhead_df = pd.DataFrame({'Body_ID': train_stances_files.Body_ID.tolist()})\nhead_df['Headline'] = clean_headlines\nbody_df = pd.DataFrame({'Body_ID': train_bodies_files.Body_ID.tolist()})\nbody_df['articleBody'] = clean_bodies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting test lists to dataframe\ntest_head_df = pd.DataFrame({'Body_ID': test_stances.Body_ID.tolist()})\ntest_head_df['Headline'] = test_clean_headlines\ntest_body_df = pd.DataFrame({'Body_ID': test_bodies.Body_ID.tolist()})\ntest_body_df['articleBody'] = test_clean_bodies","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **COMBINING BODIES AND STANCES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining Stances and Bodies datasets using \"Bosdy_ID as key\"\ncombined_data = pd.merge(head_df, body_df, on = 'Body_ID')\ncombined_test = pd.merge(test_head_df, test_body_df, on = 'Body_ID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#concatinating Headlines and articleBody\nmerge_train = list(zip(combined_data.articleBody, combined_data.Headline))\nmerge2 = [row[0]+row[1] for row in merge_train]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **VECTORIZING THE INPUT**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#tfidf fit\nprint(\"Training tf-idf\")\nvectorizer = TfidfVectorizer(max_features=1000)\ntfidfer(merge2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tfidf transform\nprint(\"transforming tf-idf\")\nbodies_tfidf_vector = transform(combined_data.articleBody)\nheadlines_tfidf_vector =transform(combined_data.Headline)\ntest_headlines_vector = transform(combined_test.Headline)\ntest_bodies_vector = transform(combined_test.articleBody)\nprint(\"transforming complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combine train headlines and bodies tfidf vectors\narr_combined = np.column_stack((headlines_tfidf_vector, bodies_tfidf_vector))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combine test headlines and bodies tfidf vectors\ntest_arr_combined = np.column_stack((test_headlines_vector, test_bodies_vector))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **DEFINING THE MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining CNN parameters\nbatch_size = 100\nnum_classes = 4\nepochs = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extracting train stances into array\ntarget = [[rows] for rows in train_stances_files.Stance]\ntarget = np.asarray(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extracting test stances into array\ntest_target = [[rows] for rows in test_stances.Stance]\ntest_target = np.asarray(test_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting to categorical\ny_train = keras.utils.to_categorical(target, num_classes)\ny_test = keras.utils.to_categorical(test_target, num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reshaping vectors for cnn\nx = np.expand_dims(arr_combined, axis =2)\nx_test = np.expand_dims(test_arr_combined, axis =2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CNN model\nprint(\"Training CNN model\")\nmodel = Sequential()\n\nmodel.add(Conv1D(32,4, padding='same', input_shape=(2000,1)))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(32,4))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Dropout(0.50))\n\nmodel.add(Flatten())\n#model.add(Dense(256))\n#model.add(Activation('relu'))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\n\nopt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **TRAINING THE MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#CNN model Fit\nmodel.fit(x, y_train,\n             batch_size=batch_size,\n             epochs=epochs,\n             validation_data=(x, y_train),\n             shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **GETTING THE RESULTS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#training performance\nscores = model.evaluate(x,y_train, verbose=1)\nprint(\"Training - Loss, Accuracy: \",scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test performance\nscores = model.evaluate(x_test,y_test, verbose=1)\nprint(\"Testing - Loss, Accuracy: \",scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test predictions\npreds = model.predict(x_test, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting predictions to stances\nf_preds =[]\nfor row in preds:\n    f_preds.append(np.where(row == row.max())[0].tolist()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting actual predictions to list\ntest_actual=[row.tolist()[0] for row in test_target]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing Results on test data\nprint(\"Confusion Matrix: \\n\", confusion_matrix(test_actual, f_preds))\nprint(classification_report(test_actual, f_preds), \"Accuracy: \", accuracy_score(test_actual, f_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}